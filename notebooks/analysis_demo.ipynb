{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import tqdm\n",
    "import argparse\n",
    "import logging\n",
    "from PIL import Image \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import data, utils, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motion Compensation and FastDVDnet model definitions take from these official github repositories\n",
    "# https://github.com/m-tassano/dvdnet\n",
    "# https://github.com/m-tassano/fastdvdnet\n",
    "\n",
    "\"\"\"\n",
    "Functions to estimate the flow between two images and compensate it.\n",
    "@author: Matias Tassano <mtassano@parisdescartes.fr>\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Parameters of the motion estimation algorithms\n",
    "def warp_flow(img, flow):\n",
    "    '''\n",
    "        Applies to img the transformation described by flow.\n",
    "    '''\n",
    "    assert len(flow.shape) == 3 and flow.shape[-1] == 2\n",
    "\n",
    "    hf, wf = flow.shape[:2]\n",
    "    # flow \t\t= -flow\n",
    "    flow[:, :, 0] += np.arange(wf)\n",
    "    flow[:, :, 1] += np.arange(hf)[:, np.newaxis]\n",
    "    res = cv2.remap(img, flow, None, cv2.INTER_LINEAR)\n",
    "    return res\n",
    "\n",
    "def estimate_invflow(img0, img1, me_algo):\n",
    "    '''\n",
    "        Estimates inverse optical flow by using the me_algo algorithm.\n",
    "    '''\n",
    "    # # # img0, img1 have to be uint8 grayscale\n",
    "    assert img0.dtype == 'uint8' and img1.dtype == 'uint8'\n",
    "\n",
    "    # Create estimator object\n",
    "    if me_algo == \"DeepFlow\":\n",
    "        of_estim = cv2.optflow.createOptFlow_DeepFlow()\n",
    "    elif me_algo == \"SimpleFlow\":\n",
    "        of_estim = cv2.optflow.createOptFlow_SimpleFlow()\n",
    "    elif me_algo == \"TVL1\":\n",
    "        of_estim = cv2.DualTVL1OpticalFlow_create()\n",
    "    else:\n",
    "        raise Exception(\"Incorrect motion estimation algorithm\")\n",
    "\n",
    "    # Run flow estimation (inverse flow)\n",
    "    flow = of_estim.calc(img1, img0, None)\n",
    "    # flow = cv.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    return flow\n",
    "\n",
    "def align_frames(img_to_align, img_source, mc_alg='DeepFlow'):\n",
    "    '''\n",
    "        Applies to img_to_align a transformation which converts it into img_source.\n",
    "        Args:\n",
    "            img_to_align: HxWxC image\n",
    "            img_source: HxWxC image\n",
    "            mc_alg: selects between DeepFlow, SimpleFlow, and TVL1. DeepFlow runs by default.\n",
    "        Returns:\n",
    "            HxWxC aligned image\n",
    "    '''\n",
    "\n",
    "    # make sure images are uint8 in the [0, 255] range\n",
    "    if img_source.max() <= 1.0:\n",
    "        img_source = (img_source*255).clip(0, 255)\n",
    "    img_source = img_source.astype(np.uint8)\n",
    "    if img_to_align.max() <= 1.0:\n",
    "        img_to_align = (img_to_align*255).clip(0, 255)\n",
    "    img_to_align = img_to_align.astype(np.uint8)\n",
    "\n",
    "    img0 = img_to_align[:, :, 0]\n",
    "    img1 = img_source[:, :, 0]\n",
    "    out_img = None\n",
    "\n",
    "    # Align frames according to selection in mc_alg\n",
    "    flow = estimate_invflow(img0, img1, mc_alg)\n",
    "\n",
    "    # rectifier\n",
    "    out_img = warp_flow(img_to_align, flow)\n",
    "\n",
    "    return out_img\n",
    "\n",
    "\"\"\"\n",
    "Definition of the FastDVDnet model\n",
    "Copyright (C) 2019, Matias Tassano <matias.tassano@parisdescartes.fr>\n",
    "This program is free software: you can use, modify and/or\n",
    "redistribute it under the terms of the GNU General Public\n",
    "License as published by the Free Software Foundation, either\n",
    "version 3 of the License, or (at your option) any later\n",
    "version. You should have received a copy of this license along\n",
    "this program. If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CvBlock(nn.Module):\n",
    "    '''(Conv2d => BN => ReLU) x 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(CvBlock, self).__init__()\n",
    "        self.convblock = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convblock(x)\n",
    "\n",
    "class InputCvBlock(nn.Module):\n",
    "    '''(Conv with num_in_frames groups => BN => ReLU) + (Conv => BN => ReLU)'''\n",
    "    def __init__(self, num_in_frames, out_ch):\n",
    "        super(InputCvBlock, self).__init__()\n",
    "        self.interm_ch = 30\n",
    "        self.convblock = nn.Sequential(\n",
    "            nn.Conv2d(num_in_frames*(3+1), num_in_frames*self.interm_ch, \\\n",
    "                      kernel_size=3, padding=1, groups=num_in_frames, bias=False),\n",
    "            nn.BatchNorm2d(num_in_frames*self.interm_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(num_in_frames*self.interm_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convblock(x)\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    '''Downscale + (Conv2d => BN => ReLU)*2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.convblock = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            CvBlock(out_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convblock(x)\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    '''(Conv2d => BN => ReLU)*2 + Upscale'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.convblock = nn.Sequential(\n",
    "            CvBlock(in_ch, in_ch),\n",
    "            nn.Conv2d(in_ch, out_ch*4, kernel_size=3, padding=1, bias=False),\n",
    "            nn.PixelShuffle(2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convblock(x)\n",
    "\n",
    "class OutputCvBlock(nn.Module):\n",
    "    '''Conv2d => BN => ReLU => Conv2d'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(OutputCvBlock, self).__init__()\n",
    "        self.convblock = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, in_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(in_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convblock(x)\n",
    "\n",
    "class DenBlock(nn.Module):\n",
    "    \"\"\" Definition of the denosing block of FastDVDnet.\n",
    "    Inputs of constructor:\n",
    "        num_input_frames: int. number of input frames\n",
    "    Inputs of forward():\n",
    "        xn: input frames of dim [N, C, H, W], (C=3 RGB)\n",
    "        noise_map: array with noise map of dim [N, 1, H, W]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_input_frames=3):\n",
    "        super(DenBlock, self).__init__()\n",
    "        self.chs_lyr0 = 32\n",
    "        self.chs_lyr1 = 64\n",
    "        self.chs_lyr2 = 128\n",
    "\n",
    "        self.inc = InputCvBlock(num_in_frames=num_input_frames, out_ch=self.chs_lyr0)\n",
    "        self.downc0 = DownBlock(in_ch=self.chs_lyr0, out_ch=self.chs_lyr1)\n",
    "        self.downc1 = DownBlock(in_ch=self.chs_lyr1, out_ch=self.chs_lyr2)\n",
    "        self.upc2 = UpBlock(in_ch=self.chs_lyr2, out_ch=self.chs_lyr1)\n",
    "        self.upc1 = UpBlock(in_ch=self.chs_lyr1, out_ch=self.chs_lyr0)\n",
    "        self.outc = OutputCvBlock(in_ch=self.chs_lyr0, out_ch=3)\n",
    "\n",
    "        self.reset_params()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\n",
    "    def reset_params(self):\n",
    "        for _, m in enumerate(self.modules()):\n",
    "            self.weight_init(m)\n",
    "\n",
    "    def forward(self, in0, in1, in2, noise_map):\n",
    "        '''Args:\n",
    "            inX: Tensor, [N, C, H, W] in the [0., 1.] range\n",
    "            noise_map: Tensor [N, 1, H, W] in the [0., 1.] range\n",
    "        '''\n",
    "        # Input convolution block\n",
    "        x0 = self.inc(torch.cat((in0, noise_map, in1, noise_map, in2, noise_map), dim=1))\n",
    "        # Downsampling\n",
    "        x1 = self.downc0(x0)\n",
    "        x2 = self.downc1(x1)\n",
    "        # Upsampling\n",
    "        x2 = self.upc2(x2)\n",
    "        x1 = self.upc1(x1+x2)\n",
    "        # Estimation\n",
    "        x = self.outc(x0+x1)\n",
    "\n",
    "        # Residual\n",
    "        x = in1 - x\n",
    "\n",
    "        return x\n",
    "\n",
    "class FastDVDnet(nn.Module):\n",
    "    \"\"\" Definition of the FastDVDnet model.\n",
    "    Inputs of forward():\n",
    "        xn: input frames of dim [N, C, H, W], (C=3 RGB)\n",
    "        noise_map: array with noise map of dim [N, 1, H, W]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_input_frames=5):\n",
    "        super(FastDVDnet, self).__init__()\n",
    "        self.num_input_frames = num_input_frames\n",
    "        # Define models of each denoising stage\n",
    "        self.temp1 = DenBlock(num_input_frames=3)\n",
    "        self.temp2 = DenBlock(num_input_frames=3)\n",
    "        # Init weights\n",
    "        self.reset_params()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\n",
    "    def reset_params(self):\n",
    "        for _, m in enumerate(self.modules()):\n",
    "            self.weight_init(m)\n",
    "\n",
    "    def forward(self, x, noise_map):\n",
    "        '''Args:\n",
    "            x: Tensor, [N, num_frames*C, H, W] in the [0., 1.] range\n",
    "            noise_map: Tensor [N, 1, H, W] in the [0., 1.] range\n",
    "        '''\n",
    "        # hack\n",
    "        N, C, H, W = x.shape\n",
    "        if(H%4 != 0):\n",
    "            x = F.pad(x, [0, 0, 4-(H%4), 0], mode = 'reflect')\n",
    "            noise_map = F.pad(noise_map, [0, 0, 4-(H%4), 0], mode = 'reflect')\n",
    "        if(W%4 != 0):\n",
    "            x = F.pad(x, [4-(W%4), 0, 0, 0], mode = 'reflect')\n",
    "            noise_map = F.pad(noise_map, [4-(W%4), 0, 0, 0], mode = 'reflect')\n",
    "        \n",
    "        # Unpack inputs\n",
    "        (x0, x1, x2, x3, x4) = tuple(x[:, 3*m:3*m+3, :, :] for m in range(self.num_input_frames))\n",
    "\n",
    "        # First stage\n",
    "        self.f1 = x20 = self.temp1(x0, x1, x2, noise_map)\n",
    "        self.f2 = x21 = self.temp1(x1, x2, x3, noise_map)\n",
    "        self.f3 = x22 = self.temp1(x2, x3, x4, noise_map)\n",
    "\n",
    "        #Second stage\n",
    "        x = self.temp2(x20, x21, x22, noise_map)\n",
    "        \n",
    "        # unhack\n",
    "        N1, C1, H1, W1 = x.shape\n",
    "        if(H%4 != 0):\n",
    "            x = x[:, :, (4-(H%4)):H1, 0:W1]\n",
    "        if(W%4 != 0):\n",
    "            x = x[:, :, 0:H, (4-(W%4)):W1]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition for loading model from a pretrained network file\n",
    "\n",
    "def load_model(PATH, Fast=False, parallel=False, pretrained=True, old=True, load_opt=False):\n",
    "    if not Fast:\n",
    "        state_dict = torch.load(PATH, map_location=\"cpu\")\n",
    "        args = argparse.Namespace(**{**vars(state_dict[\"args\"])})\n",
    "        # ignore this\n",
    "        if old:\n",
    "            vars(args)['blind_noise'] = False\n",
    "\n",
    "        model = models.build_model(args)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        model = FastDVDnet()\n",
    "    \n",
    "    if load_opt:\n",
    "        for o, state in zip([optimizer], state_dict[\"optimizer\"]):\n",
    "            o.load_state_dict(state)\n",
    "    \n",
    "    if pretrained:\n",
    "        if Fast:\n",
    "            state_dict = torch.load(PATH)\n",
    "        else:\n",
    "            state_dict = torch.load(PATH)[\"model\"][0]\n",
    "        own_state = model.state_dict()\n",
    "        \n",
    "        for name, param in state_dict.items():\n",
    "            if parallel:\n",
    "                name = name[7:]\n",
    "            if Fast:\n",
    "                name = name.split('.', 1)[1]\n",
    "            if name not in own_state:\n",
    "                print(\"here\", name)\n",
    "                continue\n",
    "            if isinstance(param, nn.Parameter):\n",
    "                # backwards compatibility for serialized parameters\n",
    "                param = param.data\n",
    "            own_state[name].copy_(param)\n",
    "        \n",
    "    if not Fast:\n",
    "        return model, optimizer, args\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE NUMBER\n",
    "example = 0 # Set 1 for another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary variable deifnitons\n",
    "\n",
    "parallel = True\n",
    "Fast = False\n",
    "pretrained = True\n",
    "old = True\n",
    "load_opt = False\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "transform = transforms.Compose([transforms.ToPILImage()])\n",
    "to_gray = transforms.Compose([transforms.ToPILImage(), transforms.Grayscale(num_output_channels=1)])\n",
    "\n",
    "dataset = \"DAVIS\"\n",
    "if example == 0:\n",
    "    video = \"giant-slalom\"\n",
    "elif example == 1:\n",
    "    video = \"bus\"\n",
    "patch_size = 128\n",
    "stride = 64\n",
    "is_image = False\n",
    "n_frames = 5\n",
    "cpf = 3\n",
    "mid = n_frames // 2\n",
    "is_real = False\n",
    "\n",
    "aug = 0\n",
    "\n",
    "dist = 'G'\n",
    "mode = 'S'\n",
    "# change noise_std parameter here to produce results at various noise levels\n",
    "noise_std = 30\n",
    "min_noise = 0\n",
    "max_noise = 100\n",
    "\n",
    "batch_size = 1\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model - UDVD\n",
    "\n",
    "PATH = \"../pretrained_models/blind_video_net.pt\"\n",
    "\n",
    "model, optimizer, args = load_model(PATH, parallel=parallel, pretrained=pretrained, old=old, load_opt=load_opt)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "\n",
    "PATH = os.path.join(\"../datasets\", dataset)\n",
    "\n",
    "train_loader, test_loader = data.build_dataset(\"SingleVideo\", PATH, batch_size=batch_size, dataset=dataset, video=video, image_size=patch_size, stride=stride, n_frames=n_frames, \n",
    "                                               aug=aug, dist=dist, mode=mode, noise_std=noise_std, min_noise=min_noise, max_noise=max_noise,\n",
    "                                               sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare frame\n",
    "\n",
    "px = 20*np.arange(0,6)+8\n",
    "py = 20*np.arange(0,6)+8\n",
    "ps, qs = np.meshgrid(px, py)\n",
    "ps = ps.reshape(-1)\n",
    "qs = qs.reshape(-1)\n",
    "\n",
    "if example == 0:\n",
    "    # giant-slalom\n",
    "    num = 109\n",
    "    x = 425; y = 115; w = 128; h = 128\n",
    "    x1 = 38; y1 = 15; w1 = 64; h1 = 64\n",
    "    ps = np.append(ps, 70); qs = np.append(qs, 47)\n",
    "elif example == 1:\n",
    "    # bus\n",
    "    num = 25 \n",
    "    x = 481; y = 219; w = 128; h = 128\n",
    "    x1 = 0; y1 = 0; w1 = 128; h1 = 128\n",
    "    ps = np.append(ps, 64); qs = np.append(qs, 64)\n",
    "\n",
    "span = 1\n",
    "\n",
    "sample = test_loader.dataset[num][0].unsqueeze(0)[:,:,y:y+h, x:x+w].to(device)\n",
    "N, C, H, W = sample.shape\n",
    "\n",
    "fixed_noises = []\n",
    "for i in range(span+5):\n",
    "    fixed_noises.append(utils.get_noise(sample[:,0:3,:,:], dist = \"G\", mode = 'S', noise_std = 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the jacobian (filters)\n",
    "\n",
    "grad_mapss = []\n",
    "pss = []; qss = [];\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for l in range(len(ps)):\n",
    "    grad_maps = []\n",
    "    p = ps[l]\n",
    "    q = qs[l]\n",
    "    pss.append([ps[l]])\n",
    "    qss.append([qs[l]])\n",
    "    for i in range(span):\n",
    "        sample = test_loader.dataset[num+i][0].unsqueeze(0)[:,:,y:y+h, x:x+w].to(device)\n",
    "        \n",
    "        clean_image = sample[:, (mid*cpf):((mid+1)*cpf), :, :]\n",
    "        if not is_real:\n",
    "            noise = (noise_std/255.0)*torch.cat(fixed_noises[i:i+5], 1)\n",
    "            noisy_inputs = noise + sample\n",
    "            noisy_frame = noisy_inputs[:, (mid*cpf):((mid+1)*cpf), :, :]\n",
    "        else:\n",
    "            noisy_inputs = sample\n",
    "            noisy_frame = clean_image\n",
    "        noisy_inputs = noisy_inputs.requires_grad_(True)\n",
    "        \n",
    "        N, C, H, W = sample.shape\n",
    "        noise_map = (noise_std/255)*torch.ones(N, 1, H, W).to(device)\n",
    "\n",
    "        if not Fast:\n",
    "            output, _ = model(noisy_inputs)\n",
    "\n",
    "            if not is_real:\n",
    "                output, mean_image = utils.post_process(output, noisy_frame, model = \"blind-video-net\", sigma = noise_std/255, device=device)\n",
    "                psnr = utils.psnr(clean_image, output)\n",
    "        else:\n",
    "            output = model(noisy_inputs, noise_map)\n",
    "            psnr = utils.psnr(clean_image, output)\n",
    "\n",
    "        loss = 100*output[:,:,q,p].mean()\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        grads = noisy_inputs.grad.cpu().detach()\n",
    "\n",
    "        grad_maps.append(grads)\n",
    "\n",
    "        img = (np.sum(grads[0,9:12,:,:].cpu().detach().numpy(), axis=0)/cpf).reshape(H, W)\n",
    "\n",
    "        ptile = 0.5*np.max(img)\n",
    "        w_sum = 0\n",
    "        p_final = 0\n",
    "        q_final = 0\n",
    "        for j in range(h):\n",
    "            for k in range(w):\n",
    "                if img[j][k] >= ptile:\n",
    "                    p_final += k*img[j][k]\n",
    "                    q_final += j*img[j][k]\n",
    "                    w_sum += img[j][k]\n",
    "        p_final /= w_sum\n",
    "        q_final /= w_sum\n",
    "        \n",
    "        pss[l].append(int(p_final))\n",
    "        qss[l].append(int(q_final))\n",
    "\n",
    "        p = int(p_final)\n",
    "        q = int(q_final)\n",
    "        \n",
    "    grad_mapss.append(grad_maps)\n",
    "    \n",
    "original_ps = np.copy(ps)\n",
    "original_qs = np.copy(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradients - Jacobian (filters)\n",
    "\n",
    "save = 0\n",
    "ps = original_ps[36:37]\n",
    "qs = original_qs[36:37]\n",
    "\n",
    "alpha = 1\n",
    "limit = 0\n",
    "for l in range(len(ps)):\n",
    "    limit = max(limit, 1*np.max(np.abs(grad_mapss[l][0].numpy())))\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    \n",
    "    ax.hlines(h1/2, xmin=0, xmax=w1, linestyles='dashed', color='gray')\n",
    "    ax.vlines(w1/2, ymin=0, ymax=h1, linestyles='dashed', color='gray')\n",
    "\n",
    "    ax.imshow(np.sum(grad_mapss[-1][0][0,i*3:(i+1)*3, y1:y1+h1, x1:x1+w1].numpy(), axis=0).reshape(w1,h1), cmap=\"seismic\",\n",
    "              vmin=-limit, vmax=limit)\n",
    "\n",
    "    rect = patches.Rectangle((0,0),w1-1,h1-1,linewidth=2,edgecolor=\"midnightblue\" ,facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    if i < 2:\n",
    "        ax.set_title(f\"Gradients at t-{2-i}\")\n",
    "    elif i == 2:\n",
    "        ax.set_title(\"Gradients at t\")\n",
    "    else:\n",
    "        ax.set_title(f\"Gradients at t+{i-2}\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    ax.set_axis_off()\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "                hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plt.figure(figsize = (3,3))\n",
    "img = plt.imshow(np.sum(grad_mapss[-1][0][0,6:9, y1:y1+h1, x1:x1+w1].numpy(), axis=0).reshape(w1,h1), \n",
    "                 cmap=\"seismic\", vmin=-limit, vmax=limit)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "cbar = plt.colorbar(img, ax=ax)\n",
    "ax.remove()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images\n",
    "\n",
    "for i in range(5):\n",
    "    pclr = 'lime'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(3,3), frameon=False)\n",
    "    ax.hlines(h1/2, xmin=0, xmax=w1, linestyles='dashed', color='white')\n",
    "    ax.vlines(w1/2, ymin=0, ymax=h1, linestyles='dashed', color='white')\n",
    "    ax.imshow(transform(test_loader.dataset[num][0][i*3:(i+1)*3, y+y1:y+y1+h1, x+x1:x+x1+w1]))\n",
    "\n",
    "    rect = patches.Rectangle((0,0),w1-1,h1-1,linewidth=2,edgecolor=\"midnightblue\" ,facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "        \n",
    "    if i < 2:\n",
    "        ax.set_title(f\"True frame at t-{2-i}\")\n",
    "    elif i == 2:\n",
    "        ax.set_title(\"True frame at t\")\n",
    "    else:\n",
    "        ax.set_title(f\"True frame at t+{i-2}\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    ax.set_axis_off()\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "                hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3), frameon=False)\n",
    "\n",
    "ax.imshow(transform(test_loader.dataset[num][0][6:9, :, :]))\n",
    "\n",
    "rect = patches.Rectangle((x+x1,y+y1),w1,h1,linewidth=1,edgecolor='midnightblue',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "ax.set_title(\"Complete frame and crop\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "plt.margins(0,0)\n",
    "ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3), frameon=False)\n",
    "\n",
    "noisy_img = np.array(transform(test_loader.dataset[num][0][6:9, y+y1:y+y1+h1, x+x1:x+x1+w1]\n",
    "                               + (noise_std/255)*fixed_noises[2][0,:, y1:y1+h1, x1:x1+w1].cpu()))\n",
    "\n",
    "ax.imshow(transform(noisy_img))\n",
    "rect = patches.Rectangle((0,0),w1-1,h1-1,linewidth=2,edgecolor='midnightblue',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "ax.set_title(\"Noisy frame\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "plt.margins(0,0)\n",
    "ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3), frameon=False)\n",
    "\n",
    "ax.hlines(h1/2, xmin=0, xmax=w1, linestyles='dashed', color='white')\n",
    "ax.vlines(w1/2, ymin=0, ymax=h1, linestyles='dashed', color='white')\n",
    "\n",
    "ax.imshow(transform(output[0,:,y1:y1+h1,x1:x1+w1].cpu().detach()))\n",
    "\n",
    "rect = patches.Rectangle((0,0),w1-1,h1-1,linewidth=2,edgecolor='midnightblue',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "ax.set_title(\"Denoised frame\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "plt.margins(0,0)\n",
    "ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calulate the arrows for Motion Compensation\n",
    "\n",
    "ps = original_ps[0:36]\n",
    "qs = original_qs[0:36]\n",
    "\n",
    "limit = 0.4\n",
    "fpss = []; fqss = []; npss = []; nqss = []\n",
    "for l in range(len(ps)):\n",
    "    fpss.append([ps[l]])\n",
    "    npss.append([ps[l]])\n",
    "    fqss.append([qs[l]])\n",
    "    nqss.append([qs[l]])\n",
    "\n",
    "for i in range(span+1):\n",
    "    img = np.array(transform(test_loader.dataset[num+i][0][6:9, y:y+h, x:x+w]))\n",
    "    noisy_img = np.array(transform(test_loader.dataset[num+i][0][6:9, y:y+h, x:x+w] + (noise_std/255)*fixed_noises[2+i][0,:,:,:].cpu()))\n",
    "\n",
    "    img0 = np.array(to_gray(test_loader.dataset[num+i][0][6:9, y:y+h, x:x+w]))\n",
    "    img1 = np.array(to_gray(test_loader.dataset[num+i][0][9:12, y:y+h, x:x+w]))\n",
    "    noisy_img0 = np.array(to_gray(test_loader.dataset[num+i][0][6:9, y:y+h, x:x+w] + (noise_std/255)*fixed_noises[2+i][0,:,:,:].cpu()))\n",
    "    noisy_img1 = np.array(to_gray(test_loader.dataset[num+i][0][9:12, y:y+h, x:x+w] + (noise_std/255)*fixed_noises[3+i][0,:,:,:].cpu()))\n",
    "    \n",
    "    flow = estimate_invflow(img0, img1, \"DeepFlow\")\n",
    "    noisy_flow = estimate_invflow(noisy_img0, noisy_img1, \"DeepFlow\")\n",
    "    for l in range(len(ps)):\n",
    "        p = fpss[l][-1]; q = fqss[l][-1]; Np = npss[l][-1]; Nq = nqss[l][-1]\n",
    "        fpss[l].append(min(p - int(flow[q][p][0]), w-1)); \n",
    "        fqss[l].append(min(q - int(flow[q][p][1]), h-1));\n",
    "        npss[l].append(min(Np - int(noisy_flow[Nq][Np][0]), w-1)); \n",
    "        nqss[l].append(min(Nq - int(noisy_flow[Nq][Np][1]), h-1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motion Compensation\n",
    "\n",
    "scale = 2\n",
    "width = 2\n",
    "head_width = 3*width\n",
    "color = \"darkorange\"\n",
    "\n",
    "img = np.array(transform(test_loader.dataset[num][0][6:9, y:y+h, x:x+w]))\n",
    "noisy_img = np.array(transform(test_loader.dataset[num][0][6:9, y:y+h, x:x+w] + (noise_std/255)*fixed_noises[2][0,:,:,:].cpu()))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), frameon=False)\n",
    "    \n",
    "ax.imshow(noisy_img)\n",
    "ax.set_title(\"Noisy frame\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), frameon=False)\n",
    "\n",
    "ax.imshow(img)\n",
    "ax.set_title(\"DeepFlow on clean video\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "for l in range(len(ps)):\n",
    "    ax.arrow(fpss[l][0], fqss[l][0], \n",
    "             scale*(fpss[l][1]-fpss[l][0]), \n",
    "             scale*(fqss[l][1]-fqss[l][0]), width=width, head_width=head_width,\n",
    "             length_includes_head=False, facecolor=color, edgecolor='midnightblue')\n",
    "    \n",
    "plt.tight_layout()\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(4,4), frameon=False)\n",
    "\n",
    "ax.imshow(img)\n",
    "ax.set_title(\"UDVD implicit motion estimation\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "for l in range(len(ps)):\n",
    "    ax.arrow(pss[l][0], qss[l][0], \n",
    "             scale*(pss[l][1]-pss[l][0]), \n",
    "             scale*(qss[l][1]-qss[l][0]), width=width, head_width=head_width,\n",
    "             length_includes_head=False, facecolor=color, edgecolor='midnightblue')\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4), frameon=False)\n",
    "\n",
    "ax.imshow(img)\n",
    "ax.set_title(\"DeepFlow on noisy video\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "for l in range(len(ps)):\n",
    "    ax.arrow(npss[l][0], nqss[l][0], \n",
    "             scale*(npss[l][1]-npss[l][0]), \n",
    "             scale*(nqss[l][1]-nqss[l][0]), width=width, head_width=head_width,\n",
    "             length_includes_head=False, facecolor=color, edgecolor='midnightblue')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
