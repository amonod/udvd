{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import tqdm\n",
    "import argparse\n",
    "import logging\n",
    "from PIL import Image \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import data, utils, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastDVDnet model definition take from their official github repository\n",
    "# https://github.com/m-tassano/fastdvdnet\n",
    "\n",
    "\"\"\"\n",
    "Definition of the FastDVDnet model\n",
    "Copyright (C) 2019, Matias Tassano <matias.tassano@parisdescartes.fr>\n",
    "This program is free software: you can use, modify and/or\n",
    "redistribute it under the terms of the GNU General Public\n",
    "License as published by the Free Software Foundation, either\n",
    "version 3 of the License, or (at your option) any later\n",
    "version. You should have received a copy of this license along\n",
    "this program. If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CvBlock(nn.Module):\n",
    "    '''(Conv2d => BN => ReLU) x 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(CvBlock, self).__init__()\n",
    "        self.convblock = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convblock(x)\n",
    "\n",
    "class InputCvBlock(nn.Module):\n",
    "    '''(Conv with num_in_frames groups => BN => ReLU) + (Conv => BN => ReLU)'''\n",
    "    def __init__(self, num_in_frames, out_ch):\n",
    "        super(InputCvBlock, self).__init__()\n",
    "        self.interm_ch = 30\n",
    "        self.convblock = nn.Sequential(\n",
    "            nn.Conv2d(num_in_frames*(3+1), num_in_frames*self.interm_ch, \\\n",
    "                      kernel_size=3, padding=1, groups=num_in_frames, bias=False),\n",
    "            nn.BatchNorm2d(num_in_frames*self.interm_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(num_in_frames*self.interm_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convblock(x)\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    '''Downscale + (Conv2d => BN => ReLU)*2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.convblock = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            CvBlock(out_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convblock(x)\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    '''(Conv2d => BN => ReLU)*2 + Upscale'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.convblock = nn.Sequential(\n",
    "            CvBlock(in_ch, in_ch),\n",
    "            nn.Conv2d(in_ch, out_ch*4, kernel_size=3, padding=1, bias=False),\n",
    "            nn.PixelShuffle(2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convblock(x)\n",
    "\n",
    "class OutputCvBlock(nn.Module):\n",
    "    '''Conv2d => BN => ReLU => Conv2d'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(OutputCvBlock, self).__init__()\n",
    "        self.convblock = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, in_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(in_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convblock(x)\n",
    "\n",
    "class DenBlock(nn.Module):\n",
    "    \"\"\" Definition of the denosing block of FastDVDnet.\n",
    "    Inputs of constructor:\n",
    "        num_input_frames: int. number of input frames\n",
    "    Inputs of forward():\n",
    "        xn: input frames of dim [N, C, H, W], (C=3 RGB)\n",
    "        noise_map: array with noise map of dim [N, 1, H, W]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_input_frames=3):\n",
    "        super(DenBlock, self).__init__()\n",
    "        self.chs_lyr0 = 32\n",
    "        self.chs_lyr1 = 64\n",
    "        self.chs_lyr2 = 128\n",
    "\n",
    "        self.inc = InputCvBlock(num_in_frames=num_input_frames, out_ch=self.chs_lyr0)\n",
    "        self.downc0 = DownBlock(in_ch=self.chs_lyr0, out_ch=self.chs_lyr1)\n",
    "        self.downc1 = DownBlock(in_ch=self.chs_lyr1, out_ch=self.chs_lyr2)\n",
    "        self.upc2 = UpBlock(in_ch=self.chs_lyr2, out_ch=self.chs_lyr1)\n",
    "        self.upc1 = UpBlock(in_ch=self.chs_lyr1, out_ch=self.chs_lyr0)\n",
    "        self.outc = OutputCvBlock(in_ch=self.chs_lyr0, out_ch=3)\n",
    "\n",
    "        self.reset_params()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\n",
    "    def reset_params(self):\n",
    "        for _, m in enumerate(self.modules()):\n",
    "            self.weight_init(m)\n",
    "\n",
    "    def forward(self, in0, in1, in2, noise_map):\n",
    "        '''Args:\n",
    "            inX: Tensor, [N, C, H, W] in the [0., 1.] range\n",
    "            noise_map: Tensor [N, 1, H, W] in the [0., 1.] range\n",
    "        '''\n",
    "        # Input convolution block\n",
    "        x0 = self.inc(torch.cat((in0, noise_map, in1, noise_map, in2, noise_map), dim=1))\n",
    "        # Downsampling\n",
    "        x1 = self.downc0(x0)\n",
    "        x2 = self.downc1(x1)\n",
    "        # Upsampling\n",
    "        x2 = self.upc2(x2)\n",
    "        x1 = self.upc1(x1+x2)\n",
    "        # Estimation\n",
    "        x = self.outc(x0+x1)\n",
    "\n",
    "        # Residual\n",
    "        x = in1 - x\n",
    "\n",
    "        return x\n",
    "\n",
    "class FastDVDnet(nn.Module):\n",
    "    \"\"\" Definition of the FastDVDnet model.\n",
    "    Inputs of forward():\n",
    "        xn: input frames of dim [N, C, H, W], (C=3 RGB)\n",
    "        noise_map: array with noise map of dim [N, 1, H, W]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_input_frames=5):\n",
    "        super(FastDVDnet, self).__init__()\n",
    "        self.num_input_frames = num_input_frames\n",
    "        # Define models of each denoising stage\n",
    "        self.temp1 = DenBlock(num_input_frames=3)\n",
    "        self.temp2 = DenBlock(num_input_frames=3)\n",
    "        # Init weights\n",
    "        self.reset_params()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\n",
    "    def reset_params(self):\n",
    "        for _, m in enumerate(self.modules()):\n",
    "            self.weight_init(m)\n",
    "\n",
    "    def forward(self, x, noise_map):\n",
    "        '''Args:\n",
    "            x: Tensor, [N, num_frames*C, H, W] in the [0., 1.] range\n",
    "            noise_map: Tensor [N, 1, H, W] in the [0., 1.] range\n",
    "        '''\n",
    "        # hack\n",
    "        N, C, H, W = x.shape\n",
    "        if(H%4 != 0):\n",
    "            x = F.pad(x, [0, 0, 4-(H%4), 0], mode = 'reflect')\n",
    "            noise_map = F.pad(noise_map, [0, 0, 4-(H%4), 0], mode = 'reflect')\n",
    "        if(W%4 != 0):\n",
    "            x = F.pad(x, [4-(W%4), 0, 0, 0], mode = 'reflect')\n",
    "            noise_map = F.pad(noise_map, [4-(W%4), 0, 0, 0], mode = 'reflect')\n",
    "        \n",
    "        # Unpack inputs\n",
    "        (x0, x1, x2, x3, x4) = tuple(x[:, 3*m:3*m+3, :, :] for m in range(self.num_input_frames))\n",
    "\n",
    "        # First stage\n",
    "        self.f1 = x20 = self.temp1(x0, x1, x2, noise_map)\n",
    "        self.f2 = x21 = self.temp1(x1, x2, x3, noise_map)\n",
    "        self.f3 = x22 = self.temp1(x2, x3, x4, noise_map)\n",
    "\n",
    "        #Second stage\n",
    "        x = self.temp2(x20, x21, x22, noise_map)\n",
    "        \n",
    "        # unhack\n",
    "        N1, C1, H1, W1 = x.shape\n",
    "        if(H%4 != 0):\n",
    "            x = x[:, :, (4-(H%4)):H1, 0:W1]\n",
    "        if(W%4 != 0):\n",
    "            x = x[:, :, 0:H, (4-(W%4)):W1]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition for loading model from a pretrained network file\n",
    "\n",
    "def load_model(PATH, Fast=False, parallel=False, pretrained=True, old=True, load_opt=False):\n",
    "    if not Fast:\n",
    "        state_dict = torch.load(PATH, map_location=\"cpu\")\n",
    "        args = argparse.Namespace(**{**vars(state_dict[\"args\"])})\n",
    "        # ignore this\n",
    "        if old:\n",
    "            vars(args)['blind_noise'] = False\n",
    "\n",
    "        model = models.build_model(args)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        model = FastDVDnet()\n",
    "    \n",
    "    if load_opt:\n",
    "        for o, state in zip([optimizer], state_dict[\"optimizer\"]):\n",
    "            o.load_state_dict(state)\n",
    "    \n",
    "    if pretrained:\n",
    "        if Fast:\n",
    "            state_dict = torch.load(PATH)\n",
    "        else:\n",
    "            state_dict = torch.load(PATH)[\"model\"][0]\n",
    "        own_state = model.state_dict()\n",
    "        \n",
    "        for name, param in state_dict.items():\n",
    "            if parallel:\n",
    "                name = name[7:]\n",
    "            if Fast:\n",
    "                name = name.split('.', 1)[1]\n",
    "            if name not in own_state:\n",
    "                print(\"here\", name)\n",
    "                continue\n",
    "            if isinstance(param, nn.Parameter):\n",
    "                # backwards compatibility for serialized parameters\n",
    "                param = param.data\n",
    "            own_state[name].copy_(param)\n",
    "        \n",
    "    if not Fast:\n",
    "        return model, optimizer, args\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary variable definitions\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "transform = transforms.Compose([transforms.ToPILImage()])\n",
    "to_gray = transforms.Compose([transforms.ToPILImage(), transforms.Grayscale(num_output_channels=1)])\n",
    "\n",
    "dataset = \"GoPro\"\n",
    "video = \"rafting\"\n",
    "patch_size = 128\n",
    "stride = 64\n",
    "is_image = False\n",
    "n_frames = 5\n",
    "cpf = 3\n",
    "mid = n_frames // 2\n",
    "is_real = False\n",
    "\n",
    "aug = 0\n",
    "\n",
    "dist = 'G'\n",
    "mode = 'S'\n",
    "# change noise_std parameter here to produce results at various noise levels\n",
    "noise_std = 30\n",
    "min_noise = 0\n",
    "max_noise = 100\n",
    "\n",
    "batch_size = 1\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "\n",
    "PATH = os.path.join(\"../datasets/Set8\", dataset)\n",
    "\n",
    "train_loader, test_loader = data.build_dataset(\"SingleVideo\", PATH, batch_size=batch_size, dataset=dataset, video=video, image_size=patch_size, stride=stride, n_frames=n_frames, \n",
    "                                               aug=aug, dist=dist, mode=mode, noise_std=noise_std, min_noise=min_noise, max_noise=max_noise,\n",
    "                                               sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame to denoise\n",
    "\n",
    "C, H, W = test_loader.dataset[0][0].shape\n",
    "\n",
    "num = 18\n",
    "x = 0; y = 0; w = W; h = H\n",
    "\n",
    "images = []\n",
    "psnrs = []\n",
    "ssims = []\n",
    "\n",
    "sample, noisy_inputs = test_loader.dataset[num]\n",
    "sample = sample[:, y:y+h, x:x+w].unsqueeze(0).to(device)\n",
    "noisy_inputs = noisy_inputs[:, y:y+h, x:x+w].unsqueeze(0).to(device)\n",
    " \n",
    "# For sampling independent new nooise\n",
    "# noisy_inputs = sample + utils.get_noise(sample, noise_std=noise_std)\n",
    "\n",
    "N, C, H, W = sample.shape\n",
    "clean_image = sample[:, 6:9, :, :]\n",
    "noisy_frame = noisy_inputs[:, 6:9, :, :]\n",
    "\n",
    "images.append(np.array(transform(clean_image[0].cpu().detach())))\n",
    "psnrs.append(utils.psnr(clean_image, clean_image))\n",
    "ssims.append(utils.ssim(clean_image, clean_image))\n",
    "\n",
    "images.append(np.array(transform(noisy_frame[0].cpu().detach())))\n",
    "psnrs.append(utils.psnr(clean_image, noisy_frame))\n",
    "ssims.append(utils.ssim(clean_image, noisy_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastDVDnet\n",
    "\n",
    "PATH = \"../pretrained_models/fast_dvd_net.pth\"\n",
    "model = load_model(PATH, Fast=True).to(device).eval()\n",
    "\n",
    "noise_map = (noise_std/255)*torch.ones(N, 1, H, W).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(noisy_inputs, noise_map)\n",
    "\n",
    "images.append(np.array(transform(output[0].cpu().detach())))\n",
    "psnrs.append(utils.psnr(clean_image, output))\n",
    "ssims.append(utils.ssim(clean_image, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDVD (1 Frame)\n",
    "\n",
    "PATH = \"../pretrained_models/blind_spot_net.pt\"\n",
    "model, _, _ = load_model(PATH, parallel=True)\n",
    "model.to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output, _ = model(noisy_frame)\n",
    "    output, mean_image = utils.post_process(output, noisy_frame, model = \"blind-video-net\", sigma = noise_std/255, device=device)\n",
    "\n",
    "images.append(np.array(transform(output[0].cpu().detach())))\n",
    "psnrs.append(utils.psnr(clean_image, output))\n",
    "ssims.append(utils.ssim(clean_image, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDVD\n",
    "\n",
    "PATH = \"../pretrained_models/blind_video_net.pt\"\n",
    "model, _, _ = load_model(PATH, parallel=True)\n",
    "model.to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output, _ = model(noisy_inputs)\n",
    "    output, mean_image = utils.post_process(output, noisy_frame, model = \"blind-video-net\", sigma = noise_std/255, device=device)\n",
    "\n",
    "images.append(np.array(transform(output[0].cpu().detach())))\n",
    "psnrs.append(utils.psnr(clean_image, output))\n",
    "ssims.append(utils.ssim(clean_image, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDVD (single video)\n",
    "\n",
    "PATH = \"../pretrained_models/single_video_Set8_rafting_30.pt\"\n",
    "\n",
    "model, _, _ = load_model(PATH, parallel=True, old=False)\n",
    "model.to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output, _ = model(noisy_inputs)\n",
    "    output, mean_image = utils.post_process(output, noisy_frame, model = \"blind-video-net\", sigma = noise_std/255, device=device)\n",
    "\n",
    "images.append(np.array(transform(output[0].cpu().detach())))\n",
    "psnrs.append(utils.psnr(clean_image, output))\n",
    "ssims.append(utils.ssim(clean_image, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting all images for comparison\n",
    "\n",
    "names = [\"Ground Truth\", \"Noisy Frame\", \"FastDVDnet\", \"Blind-spot\", \"UDVD\", \"UDVD (single-video)\"]\n",
    "\n",
    "for i in range(6):\n",
    "    fig, ax = plt.subplots(figsize=(5, (9/16)*5))\n",
    "    \n",
    "    ax.imshow(images[i])\n",
    "    ax.set_title(\"%s, PSNR/SSIM = %.3f/%.3f\" % (names[i], psnrs[i], ssims[i]))\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDVD - example video gif\n",
    "# Change model definition according to the code above for denoised videos of different models\n",
    "\n",
    "PATH = \"../pretrained_models/blind_video_net.pt\"\n",
    "model, _, _ = load_model(PATH, parallel=True)\n",
    "model.to(device).eval()\n",
    "\n",
    "frames = []\n",
    "os.makedirs(os.path.join(\"..\", \"example_videos\", video), exist_ok=True)\n",
    "save_dir = os.path.join(\"..\", \"example_videos\", video)\n",
    "C, H, W = test_loader.dataset[0][0].shape\n",
    "w = W; h = H; x = 0; y = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (sample, noisy_inputs) in enumerate(test_loader):\n",
    "        sample = sample[:,:,y:y+h,x:x+w].to(device)\n",
    "        noisy_inputs = noisy_inputs[:,:,y:y+h,x:x+w].to(device)\n",
    "        \n",
    "        N, C, H, W = sample.shape\n",
    "        clean_image = sample[:, 6:9, :, :]\n",
    "        noisy_frame = noisy_inputs[:, 6:9, :, :]\n",
    "        \n",
    "        output, _ = model(noisy_inputs)\n",
    "        output, mean_image = utils.post_process(output, noisy_frame, model = \"blind-video-net\", sigma = noise_std/255, device=device)\n",
    "        \n",
    "        img = np.array(transform(output[0].cpu().detach()))\n",
    "        noisy_img = np.array(transform(noisy_frame[0].cpu().detach()))\n",
    "        \n",
    "        frame = cv2.cvtColor(np.append(noisy_img, img, axis=0), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        cv2.line(frame, (0,H), (W,H), (0,0,255), 1)\n",
    "        \n",
    "        cv2.imwrite(os.path.join(save_dir, \"%05d.jpg\" % (i)), frame)\n",
    "        \n",
    "        frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining frames into mp4 video\n",
    "\n",
    "fps = 30\n",
    "video_path = os.path.join(save_dir, f\"{video}.mp4\")\n",
    "height, width, layers = frames[0].shape\n",
    "out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'MJPG'), fps, (width, height))\n",
    "for i in range(len(frames)):\n",
    "    out.write(frames[i])\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting mp4 to a gif video (optional)\n",
    "\n",
    "from moviepy.editor import *\n",
    "\n",
    "video_path = os.path.join(save_dir, f\"{video}.mp4\")\n",
    "gif_path = os.path.join(save_dir, f\"{video}.gif\")\n",
    "\n",
    "clip = (VideoFileClip(video_path).resize(0.5))\n",
    "clip.write_gif(gif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
