{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import tqdm\n",
    "import argparse\n",
    "import logging\n",
    "from PIL import Image \n",
    "import skimage\n",
    "import skimage.io\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import data, utils, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(PATH, parallel=True, pretrained=True, old=True, load_opt=False):\n",
    "    state_dict = torch.load(PATH, map_location=\"cpu\")\n",
    "    args = argparse.Namespace(**{**vars(state_dict[\"args\"])})\n",
    "    if old:\n",
    "        vars(args)['blind_noise'] = False\n",
    "    \n",
    "    model = models.build_model(args)\n",
    "    # model.load_state_dict(state_dict[\"model\"][0])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    if load_opt:\n",
    "        for o, state in zip([optimizer], state_dict[\"optimizer\"]):\n",
    "            o.load_state_dict(state)\n",
    "    \n",
    "    if pretrained:\n",
    "        state_dict = torch.load(PATH)[\"model\"][0]\n",
    "        own_state = model.state_dict()\n",
    "        # print(own_state)\n",
    "\n",
    "        for name, param in state_dict.items():\n",
    "            if parallel:\n",
    "                name = name[7:]\n",
    "            if name not in own_state:\n",
    "                print(\"here\", name)\n",
    "                continue\n",
    "            if isinstance(param, nn.Parameter):\n",
    "                # backwards compatibility for serialized parameters\n",
    "                param = param.data\n",
    "            own_state[name].copy_(param)\n",
    "        \n",
    "    return model, optimizer, args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlindVideoNet(\n",
      "  (rotate): rotate()\n",
      "  (denoiser_1): Blind_UNet(\n",
      "    (enc1): ENC_Conv(\n",
      "      (conv1): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv3): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (pool): Pool(\n",
      "        (shift): shift(\n",
      "          (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "          (crop): crop()\n",
      "        )\n",
      "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (enc2): ENC_Conv(\n",
      "      (conv1): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv3): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (pool): Pool(\n",
      "        (shift): shift(\n",
      "          (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "          (crop): crop()\n",
      "        )\n",
      "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (enc3): ENC_Conv(\n",
      "      (conv1): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv3): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (dec2): DEC_Conv(\n",
      "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (conv1): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv3): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv4): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (dec1): DEC_Conv(\n",
      "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (conv1): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(99, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv3): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv4): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (denoiser_2): Blind_UNet(\n",
      "    (enc1): ENC_Conv(\n",
      "      (conv1): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv3): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (pool): Pool(\n",
      "        (shift): shift(\n",
      "          (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "          (crop): crop()\n",
      "        )\n",
      "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (enc2): ENC_Conv(\n",
      "      (conv1): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv3): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (pool): Pool(\n",
      "        (shift): shift(\n",
      "          (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "          (crop): crop()\n",
      "        )\n",
      "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (enc3): ENC_Conv(\n",
      "      (conv1): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv3): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (dec2): DEC_Conv(\n",
      "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (conv1): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv3): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv4): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (dec1): DEC_Conv(\n",
      "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (conv1): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv3): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (conv4): Conv(\n",
      "        (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "        (crop): crop()\n",
      "        (replicate): ReplicationPad2d((1, 1, 1, 1))\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (shift): shift(\n",
      "    (shift_down): ZeroPad2d(padding=(0, 0, 1, 0), value=0.0)\n",
      "    (crop): crop()\n",
      "  )\n",
      "  (unrotate): unrotate()\n",
      "  (nin_A): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (nin_B): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (nin_C): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# PATH = \"/scratch/ds6516/video_denoising/experiments/blind-video-net-4/raw-video-BF-0-100-Mar-14-05:36:55/checkpoints/checkpoint_best.pt\"\n",
    "PATH = \"/scratch/ds6516/video_denoising/experiments/blind-video-net-4/raw-video-BF-0-100-Mar-15-01:56:48/checkpoints/checkpoint_best.pt\"\n",
    "# PATH = \"/scratch/ds6516/video_denoising/experiments/blind-video-net-4/raw-iso25600-BF-0-100-Mar-15-07:20:36/checkpoints/checkpoint_best.pt\"\n",
    "\n",
    "model, optimizer, args = load_model(PATH)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawVideo(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path, datatype=\"train\", patch_size=None, stride=64, n_frames=5, aug=0,\n",
    "                 scenes=[7, 8, 9, 10, 11],\n",
    "                 isos = [1600, 3200, 6400, 12800, 25600]):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.datatype = datatype\n",
    "        self.size = patch_size\n",
    "        self.stride = stride\n",
    "        self.n_frames = n_frames\n",
    "        self.aug = aug\n",
    "        \n",
    "        self.noisy_path = os.path.join(self.data_path, \"indoor_raw_noisy\")\n",
    "        self.gt_path = os.path.join(self.data_path, \"indoor_raw_gt\")\n",
    "        self.scenes = scenes\n",
    "        self.isos = isos\n",
    "        if self.datatype == \"train\":\n",
    "            self.nr = 9 # noise_realisations\n",
    "        elif self.datatype == \"val\":\n",
    "            self.nr = 1 # only the 9th noise realisation used for heldout\n",
    "        elif self.datatype == \"test\":\n",
    "            self.nr = 10\n",
    "        self.fpv = self.bound = 7 # frames_per_video\n",
    "        \n",
    "        self.len = self.fpv * self.nr * len(self.isos) * len(self.scenes)\n",
    "        \n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.reverse = transforms.Compose([transforms.ToPILImage()])\n",
    "\n",
    "        Img = skimage.io.imread(os.path.join(self.noisy_path, f\"scene{self.scenes[0]}\", \n",
    "                                             f\"ISO{self.isos[0]}\", \"frame1_noisy0.tiff\"))\n",
    "        H, W = Img.shape\n",
    "        \n",
    "        if self.size is not None:\n",
    "            self.n_H = (int((H-self.size)/self.stride)+1)\n",
    "            self.n_W = (int((W-self.size)/self.stride)+1)\n",
    "            self.n_patches = self.n_H * self.n_W\n",
    "            self.len *= self.n_patches\n",
    "\n",
    "        self.hflip = transforms.Compose([transforms.RandomHorizontalFlip(p=1)])\n",
    "        self.vflip = transforms.Compose([transforms.RandomVerticalFlip(p=1)])\n",
    "\n",
    "        if aug >= 1: # Horizonatal and Vertical Flips\n",
    "            self.len *= 4\n",
    "        if aug >= 2: # Reverse the Video\n",
    "            self.len *= 2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hop = 1\n",
    "        reverse = 0\n",
    "        flip = 0\n",
    "        if self.aug >= 2: # Reverse the Video\n",
    "            reverse = index % 2\n",
    "            index = index // 2\n",
    "        if self.aug >= 1: # Horizonatal and Vertical Flips\n",
    "            flip = index % 4\n",
    "            index = index // 4\n",
    "\n",
    "        if self.size is not None:\n",
    "            patch = index % self.n_patches\n",
    "            index = index // self.n_patches\n",
    "            \n",
    "        scene = index % len(self.scenes)\n",
    "        index = index // len(self.scenes)\n",
    "        \n",
    "        iso = index % len(self.isos)\n",
    "        index = index // len(self.isos)\n",
    "        \n",
    "        if self.datatype == \"val\":\n",
    "            nr = 9\n",
    "        else:\n",
    "            nr = index % self.nr\n",
    "            index = index // self.nr\n",
    "        \n",
    "#         print(scene, iso, nr, index)\n",
    "        \n",
    "        ends = 0\n",
    "        x = ((self.n_frames-1) // 2)*hop\n",
    "        if index < x:\n",
    "            ends = x - index\n",
    "        elif self.bound-1-index < x:\n",
    "            ends = -(x-(self.bound-1-index))\n",
    "\n",
    "        Img = skimage.io.imread(os.path.join(self.gt_path, \n",
    "                                             f\"scene{self.scenes[scene]}\",\n",
    "                                             f\"ISO{self.isos[iso]}\", \n",
    "                                             f\"frame{index+1}_clean_and_slightly_denoised.tiff\"))\n",
    "        H, W = Img.shape\n",
    "        Img = Img.reshape(H, W, 1)\n",
    "        noisy_Img = skimage.io.imread(os.path.join(self.noisy_path, \n",
    "                                             f\"scene{self.scenes[scene]}\",\n",
    "                                             f\"ISO{self.isos[iso]}\", \n",
    "                                             f\"frame{index+1}_noisy{nr}.tiff\"))\n",
    "        noisy_Img = noisy_Img.reshape(H, W, 1)\n",
    "\n",
    "        for i in range(hop, x+1, hop):\n",
    "            end = max(0, ends)\n",
    "            off = max(0,i-x+end)\n",
    "#             print(index-i+off)\n",
    "            # img = Image.open(self.files[index-i+off])\n",
    "            img = skimage.io.imread(os.path.join(self.gt_path, \n",
    "                                             f\"scene{self.scenes[scene]}\",\n",
    "                                             f\"ISO{self.isos[iso]}\", \n",
    "                                             f\"frame{index-i+off+1}_clean_and_slightly_denoised.tiff\"))\n",
    "            img = img.reshape(H, W, 1)\n",
    "            # noisy_img = np.load(self.noisy_files[index-i+off])\n",
    "            noisy_img = skimage.io.imread(os.path.join(self.noisy_path, \n",
    "                                             f\"scene{self.scenes[scene]}\",\n",
    "                                             f\"ISO{self.isos[iso]}\", \n",
    "                                             f\"frame{index-i+off+1}_noisy{nr}.tiff\"))\n",
    "            noisy_img = noisy_img.reshape(H, W, 1)\n",
    "            \n",
    "            if reverse == 0:\n",
    "                Img = np.concatenate((img, Img), axis=2)\n",
    "                noisy_Img = np.concatenate((noisy_img, noisy_Img), axis=2)\n",
    "            else:\n",
    "                Img = np.concatenate((Img, img), axis=2)\n",
    "                noisy_Img = np.concatenate((noisy_Img, noisy_img), axis=2)\n",
    "\n",
    "        for i in range(hop, x+1, hop):\n",
    "            end = -min(0,ends)\n",
    "            off = max(0,i-x+end)\n",
    "#             print(index+i-off)\n",
    "            # img = Image.open(self.files[index+i-off])\n",
    "            img = skimage.io.imread(os.path.join(self.gt_path, \n",
    "                                             f\"scene{self.scenes[scene]}\",\n",
    "                                             f\"ISO{self.isos[iso]}\", \n",
    "                                             f\"frame{index+i-off+1}_clean_and_slightly_denoised.tiff\"))\n",
    "            img = img.reshape(H, W, 1)\n",
    "            # noisy_img = np.load(self.noisy_files[index+i-off])\n",
    "            noisy_img = skimage.io.imread(os.path.join(self.noisy_path, \n",
    "                                             f\"scene{self.scenes[scene]}\",\n",
    "                                             f\"ISO{self.isos[iso]}\", \n",
    "                                             f\"frame{index+i-off+1}_noisy{nr}.tiff\"))\n",
    "            noisy_img = noisy_img.reshape(H, W, 1)\n",
    "            \n",
    "            if reverse == 0:\n",
    "                Img = np.concatenate((Img, img), axis=2)\n",
    "                noisy_Img = np.concatenate((noisy_Img, noisy_img), axis=2)\n",
    "            else:\n",
    "                Img = np.concatenate((img, Img), axis=2)\n",
    "                noisy_Img = np.concatenate((noisy_img, noisy_Img), axis=2)\n",
    "\n",
    "        if self.size is not None:\n",
    "            nh = (patch // self.n_W)*self.stride\n",
    "            nw = (patch % self.n_W)*self.stride\n",
    "            Img = Img[nh:(nh+self.size), nw:(nw+self.size), :]\n",
    "            noisy_Img = noisy_Img[nh:(nh+self.size), nw:(nw+self.size), :]\n",
    "\n",
    "        if flip == 1:\n",
    "            Img = np.flip(Img, 1)\n",
    "            noisy_Img = np.flip(noisy_Img, 1)\n",
    "        elif flip == 2:\n",
    "            Img = np.flip(Img, 0)\n",
    "            noisy_Img = np.flip(noisy_Img, 0)\n",
    "        elif flip == 3:\n",
    "            Img = np.flip(Img, (1,0))\n",
    "            noisy_Img = np.flip(noisy_Img, (1,0))\n",
    "        \n",
    "        Img = Img.astype(np.float32)\n",
    "        noisy_Img = noisy_Img.astype(np.float32)\n",
    "#         print(Img.max(), Img.min(), noisy_Img.max(), noisy_Img.min())\n",
    "        Img = (Img-240.)/(2**12-1-240)\n",
    "        noisy_Img = (noisy_Img-240.)/(2**12-1-240)\n",
    "#         print(Img.max(), Img.min(), noisy_Img.max(), noisy_Img.min())\n",
    "\n",
    "        # return self.transform(np.array(Img)).type(torch.FloatTensor)\n",
    "        # return self.transform(np.array(Img)).type(torch.FloatTensor), torch.from_numpy(noisy_Img.copy())\n",
    "        return self.transform(np.array(Img)).type(torch.FloatTensor), self.transform(np.array(noisy_Img)).type(torch.FloatTensor)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/scratch/ds6516/video_denoising/datasets/RawVideo\"\n",
    "\n",
    "# dataset = RawVideo(path, datatype=\"train\", patch_size=128, stride=64, aug=0)\n",
    "# dataset = RawVideo(path, datatype=\"val\", patch_size=1080, stride=1920-1080)\n",
    "dataset = RawVideo(path, datatype=\"val\", patch_size=1080, stride=1920-1080, isos=[25600])\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: valid_psnr 42.113 | valid_ssim 0.995 | lr 1.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "model.eval()\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=1, num_workers=1, shuffle=False)\n",
    "\n",
    "cpf = 1\n",
    "mid = 2\n",
    "\n",
    "valid_meters = {name: utils.AverageMeter() for name in ([\"valid_psnr\", \"valid_ssim\"])}\n",
    "\n",
    "model.eval()\n",
    "for meter in valid_meters.values():\n",
    "    meter.reset()\n",
    "\n",
    "valid_bar = utils.ProgressBar(valid_loader)\n",
    "running_valid_psnr = 0.0\n",
    "plist = []\n",
    "slist = []\n",
    "for sample_id, (sample, noisy_inputs) in enumerate(valid_bar):\n",
    "    with torch.no_grad():\n",
    "        sample = sample.to(device)\n",
    "        noisy_inputs = noisy_inputs.to(device)\n",
    "        \n",
    "        outputs, est_sigma = model(noisy_inputs)\n",
    "        \n",
    "        valid_psnr = utils.psnr(sample[:, (mid*cpf):((mid+1)*cpf), :, :], outputs, normalized=False, raw=True)\n",
    "        valid_ssim = utils.ssim(sample[:, (mid*cpf):((mid+1)*cpf), :, :], outputs, normalized=False, raw=True)\n",
    "        plist.append(valid_psnr)\n",
    "        slist.append(valid_ssim)\n",
    "        running_valid_psnr += valid_psnr\n",
    "        valid_meters[\"valid_psnr\"].update(valid_psnr.item())\n",
    "        valid_meters[\"valid_ssim\"].update(valid_ssim.item())\n",
    "        \n",
    "        valid_bar.log(dict(**valid_meters, lr=optimizer.param_groups[0][\"lr\"]), verbose=True)\n",
    "        \n",
    "running_valid_psnr /= (sample_id+1)\n",
    "print(\"EVAL: \"+valid_bar.print(dict(**valid_meters, lr=optimizer.param_groups[0][\"lr\"])))\n",
    "# print(plist)\n",
    "# print(slist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [raw-random-eval-full] (43.97) EVAL: valid_psnr 42.952 | valid_ssim 0.996 | lr 1.0e-04\n",
    "- [raw-random-eval-full-ISO25600] (41.17) EVAL: valid_psnr 40.939 | valid_ssim 0.994 | lr 1.0e-04\n",
    "- [raw-random-eval-full-ISO1600] (47.74) EVAL: valid_psnr 45.881 | valid_ssim 0.998 | lr 1.0e-04\n",
    "- \n",
    "- [raw-full] EVAL: valid_psnr 44.075 | valid_ssim 0.997 | lr 1.0e-04\n",
    "- [raw-full-ISO1600] EVAL: valid_psnr 47.927 | valid_ssim 0.998 | lr 1.0e-04 (latest)\n",
    "- [raw-full-ISO3200] EVAL: valid_psnr 45.844 | valid_ssim 0.998 | lr 1.0e-04\n",
    "- [raw-full-ISO6400] EVAL: valid_psnr 44.092 | valid_ssim 0.997 | lr 1.0e-04\n",
    "- [raw-full-ISO12800] EVAL: valid_psnr 41.512 | valid_ssim 0.996 | lr 1.0e-04\n",
    "- [raw-full-ISO25600] EVAL: valid_psnr 41.515 | valid_ssim 0.994 | lr 1.0e-04\n",
    "-\n",
    "- [raw-ISO25600] EVAL: valid_psnr 41.375 | valid_ssim 0.994 | lr 1.0e-04\n",
    "-\n",
    "- EVAL: valid_psnr 44.694 | valid_ssim 0.997 | lr 1.0e-04\n",
    "- [1600] EVAL: valid_psnr 48.036 | valid_ssim 0.998 | lr 1.0e-04\n",
    "- [3200] EVAL: valid_psnr 46.424 | valid_ssim 0.998 | lr 1.0e-04\n",
    "- [6400] EVAL: valid_psnr 44.705 | valid_ssim 0.997 | lr 1.0e-04\n",
    "- [12800] EVAL: valid_psnr 42.189 | valid_ssim 0.997 | lr 1.0e-04\n",
    "- [25600] EVAL: valid_psnr 42.113 | valid_ssim 0.995 | lr 1.0e-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = 0\n",
    "x = 120; y = 120; w = 320; h = 320\n",
    "bright = 0.6\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i in [5,7,9]:\n",
    "        inputs = dataset[i][1].unsqueeze(0).to(device)\n",
    "        outputs, _ = model(inputs)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(3,3))\n",
    "        \n",
    "        img = inputs[0,2,:,:].cpu().detach().numpy()\n",
    "#         ax.imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "        img = np.uint16(img * (2**12-1-240) + 240)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BayerGR2RGB)\n",
    "        img = (img-240.)/(2**12-1-240)\n",
    "        ax.imshow(img[y:y+h, x:x+w, :]/bright)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save==1:\n",
    "            plt.savefig(f\"./plots/raw_videos/scene_11_{i}_noisy.pdf\", bbox_inches=\"tight\", pad_inches=0)\n",
    "            plt.close()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(3,3))\n",
    "        \n",
    "        img = outputs[0,0,:,:].cpu().detach().numpy()\n",
    "#         ax.imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "        img = np.uint16(img * (2**12-1-240) + 240)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BayerGR2RGB)\n",
    "        img = (img-240.)/(2**12-1-240)\n",
    "        ax.imshow(img[y:y+h, x:x+w, :]/bright)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save==1:\n",
    "            plt.savefig(f\"./plots/raw_videos/scene_11_{i}_denoised.pdf\", bbox_inches=\"tight\", pad_inches=0)\n",
    "            plt.close()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(3,3))\n",
    "        \n",
    "        img = dataset[i][0][2,:,:].cpu().detach().numpy()\n",
    "#         ax.imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "        img = np.uint16(img * (2**12-1-240) + 240)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BayerGR2RGB)\n",
    "        img = (img-240.)/(2**12-1-240)\n",
    "        ax.imshow(img[y:y+h, x:x+w, :]/bright)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save==1:\n",
    "            plt.savefig(f\"./plots/raw_videos/scene_11_{i}_clean.pdf\", bbox_inches=\"tight\", pad_inches=0)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = 0\n",
    "\n",
    "# num = 9 \n",
    "# aux = 11\n",
    "# x = 100; y = 50; w = 320; h = 320; p = w // 2; q = h // 2;\n",
    "\n",
    "num = 9 \n",
    "aux = 10\n",
    "x = 32; y = 200; w = 256; h = 256; p = w // 2; q = h // 2;\n",
    "\n",
    "bright = 0.6\n",
    "\n",
    "model.train()\n",
    "\n",
    "inputs = dataset[num][1].unsqueeze(0)[:,:,y:y+h, x:x+w].to(device).requires_grad_(True)\n",
    "\n",
    "outputs, _ = model(inputs)\n",
    "\n",
    "loss = 100*outputs[0,0,q,p]\n",
    "\n",
    "model.zero_grad()\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "grads = inputs.grad.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 0.3*np.max(np.abs(grads))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "# ax.imshow(inputs[0,2,:,:].cpu().detach().numpy(), cmap=\"gray\", vmin=0, vmax=1)\n",
    "img = inputs[0,2,:,:].cpu().detach().numpy()\n",
    "img = np.uint16(img * (2**12-1-240) + 240)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BayerGR2RGB)\n",
    "img = (img-240.)/(2**12-1-240)\n",
    "ax.imshow(img/bright)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# DO NOT TOUCH\n",
    "ax.set_axis_off()\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "plt.margins(0,0)\n",
    "ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "##############\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save == 1:\n",
    "    plt.savefig(f\"./plots/raw_videos/input_{aux}_{num}.pdf\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "# ax.imshow(outputs[0,0,:,:].cpu().detach().numpy(), cmap=\"gray\", vmin=0, vmax=1)\n",
    "img = outputs[0,0,:,:].cpu().detach().numpy()\n",
    "img = np.uint16(img * (2**12-1-240) + 240)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BayerGR2RGB)\n",
    "img = (img-240.)/(2**12-1-240)\n",
    "ax.imshow(img/bright)\n",
    "# rect = patches.Rectangle((p-1,q-1),2,2,linewidth=1,edgecolor='r',facecolor='r')\n",
    "# ax.add_patch(rect)\n",
    "# circle = patches.Circle((p,q), radius=2, color='r')\n",
    "# ax.add_patch(circle)\n",
    "ax.hlines(h/2, xmin=0, xmax=w, linestyles='dashed', color='r')\n",
    "ax.vlines(w/2, ymin=0, ymax=h, linestyles='dashed', color='r')\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# DO NOT TOUCH\n",
    "ax.set_axis_off()\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "plt.margins(0,0)\n",
    "ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "##############\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save == 1:\n",
    "    plt.savefig(f\"./plots/raw_videos/output_{aux}_{num}.pdf\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "for i in range(5):\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    \n",
    "    ax.imshow(grads[0,i,:,:], cmap=\"seismic\", vmin=-limit, vmax=limit)\n",
    "#     rect = patches.Rectangle((p-1,q-1),2,2,linewidth=1,edgecolor='limegreen',facecolor='none')\n",
    "#     ax.add_patch(rect)\n",
    "#     if i==2:\n",
    "#         poly = patches.RegularPolygon((p-1,q-1), numVertices=3, radius=3, color='limegreen')\n",
    "#         ax.add_patch(poly)\n",
    "#     else:\n",
    "#         circle = patches.Circle((p-1,q-1), radius=2, color='limegreen')\n",
    "#         ax.add_patch(circle)\n",
    "\n",
    "    ax.hlines(h/2, xmin=0, xmax=w, linestyles='dashed', color='gray')\n",
    "    ax.vlines(w/2, ymin=0, ymax=h, linestyles='dashed', color='gray')\n",
    "    \n",
    "    rect = patches.Rectangle((0,0),w-1,h-1,linewidth=2,edgecolor=\"midnightblue\" ,facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    # DO NOT TOUCH\n",
    "    ax.set_axis_off()\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "                hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "    ##############\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save == 1:\n",
    "        plt.savefig(f\"./plots/raw_videos/grads_{aux}_{num}_{i}.pdf\", bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "    \n",
    "plt.figure(figsize = (3,3))\n",
    "img = plt.imshow(grads[0,2,:,:], cmap=\"seismic\", vmin=-limit, vmax=limit)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "cbar = plt.colorbar(img, ax=ax)\n",
    "ax.remove()\n",
    "plt.tight_layout()\n",
    "\n",
    "if save == 1:\n",
    "    plt.savefig(f\"./plots/raw_videos/cbar_{aux}_{num}.pdf\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(grads[0,2,:,:]), dataset.data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"scene_10\"\n",
    "bright = 0.6\n",
    "\n",
    "model.eval()\n",
    "\n",
    "frames = []\n",
    "os.makedirs(os.path.join(dataset.data_path, \"denoised\"), exist_ok=True)\n",
    "save_dir = os.path.join(dataset.data_path, \"denoised\")\n",
    "C, H, W = dataset[0][1].shape\n",
    "x = 0; y = 540; w = 540; h = 540\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in [1,3,5,7,9,11,13]:\n",
    "        noisy_inputs = dataset[i][1].unsqueeze(0)\n",
    "        noisy_inputs = noisy_inputs[:,:,y:y+h,x:x+w].to(device)\n",
    "        \n",
    "        N, C, H, W = noisy_inputs.shape\n",
    "        noisy_frame = noisy_inputs[:, 2:3, :, :]\n",
    "        \n",
    "        output, _ = model(noisy_inputs)\n",
    "        \n",
    "        img = np.array(output[0,0,:,:].cpu().detach())\n",
    "        img = np.uint16(img * (2**12-1-240) + 240)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BayerGR2BGR)\n",
    "        img = (img-240.)/(2**12-1-240)\n",
    "        img /= bright\n",
    "        img *= 255\n",
    "        img = np.uint8(np.clip(img, 0, 255))\n",
    "        \n",
    "        noisy_img = np.array(noisy_frame[0,0,:,:].cpu().detach())\n",
    "        noisy_img = np.uint16(noisy_img * (2**12-1-240) + 240)\n",
    "        noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_BayerGR2BGR)\n",
    "        noisy_img = (noisy_img-240.)/(2**12-1-240)\n",
    "        noisy_img /= bright\n",
    "        noisy_img *= 255\n",
    "        noisy_img = np.uint8(np.clip(noisy_img, 0, 255))\n",
    "        \n",
    "        frame = np.append(noisy_img, img, axis=1)\n",
    "        cv2.line(frame, (W,0), (W,H), (0,0,0), 1)\n",
    "        \n",
    "        cv2.imwrite(os.path.join(save_dir, \"%05d.jpg\" % (i)), frame)\n",
    "        \n",
    "        frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 12\n",
    "\n",
    "video_path = os.path.join(save_dir, f\"{video}.mp4\")\n",
    "height, width, layers = frames[0].shape\n",
    "out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'MJPG'), fps, (width, height))\n",
    "for i in range(len(frames)):\n",
    "    out.write(frames[i])\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  57%|█████▋    | 4/7 [00:00<00:00, 26.43it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file /scratch/ds6516/video_denoising/datasets/RawVideo/denoised/scene_10.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "video_path = os.path.join(save_dir, f\"{video}.mp4\")\n",
    "gif_path = os.path.join(save_dir, f\"{video}.gif\")\n",
    "\n",
    "clip = (VideoFileClip(video_path).resize(0.5))\n",
    "clip.write_gif(gif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import compare_psnr,compare_ssim\n",
    "\n",
    "utils.psnr(dataset[0][0].unsqueeze(0)[:,2:3,:,:], dataset[0][1].unsqueeze(0)[:,2:3,:,:], raw=False)\n",
    "\n",
    "# print(compare_psnr(dataset[0][0][2].numpy(), dataset[0][1][2].numpy(), data_range=1.0))\n",
    "# print(compare_ssim(dataset[0][0][2].numpy(), dataset[0][1][2].numpy(), data_range=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = dataset[0][1].unsqueeze(0).to(device)[:,:,:1080,:1080]\n",
    "    outputs, _ = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = np.zeros((5,3,100,100))\n",
    "noisy = np.zeros((5,3,100,100))\n",
    "noisy.transpose(0,2,3,1).shape\n",
    "# for c, n in zip(clean, noisy):\n",
    "#     print(c[0].shape, n[0].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(dataset.gt_path, \n",
    "             f\"scene{dataset.scenes[1]}\",\n",
    "             f\"ISO{dataset.isos[1]}\", \n",
    "             f\"frame{1}_clean_and_slightly_denoised.tiff\")\n",
    "\n",
    "img = skimage.io.imread(path)\n",
    "img.max(), img.min(), path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_gt = cv2.imread('../../my_raw_video_recorded_from_current_HuaweiCamera/indoor_raw_test_gt_slightly_denoised/scene{}/ISO{}/frame{}_clean_and_slightly_denoised.tiff'.format(scene_id, iso, i),-1).astype(np.float32)\n",
    "# test_gt = (test_gt-240)/(2**12-1-240)\n",
    "\n",
    "# test_raw_psnr = compare_psnr(test_gt,(np.uint16(test_result*(2**12-1-240)+240).astype(np.float32)-240)/(2**12-1-240), data_range=1.0)\n",
    "# test_raw_ssim = compute_ssim_for_packed_raw(test_gt, (np.uint16(test_result*(2**12-1-240)+240).astype(np.float32)-240)/(2**12-1-240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# import cv2\n",
    "\n",
    "img1 = Image.open(\"./datasets/RawVideo/indoor_raw_noisy/scene1/ISO25600/frame1_noisy0.tiff\")\n",
    "img2 = Image.open(\"./datasets/RawVideo/indoor_raw_gt/scene1/ISO25600/frame1_clean_and_slightly_denoised.tiff\")\n",
    "# img = cv2.imread(\"./datasets/RawVideo/indoor_raw_noisy/scene1/ISO25600/frame1_noisy0.tiff\")\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BayerGB2RGB)\n",
    "img1 = np.array(img1)\n",
    "img2 = np.array(img2)\n",
    "img1 = (img1 - img1.min())\n",
    "img1 = img1/img1.max()\n",
    "img2 = (img2 - img2.min())\n",
    "img2 = img2/img2.max()\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(20,20))\n",
    "axs[0].imshow(img1, cmap=\"gray\")\n",
    "axs[0].axis(\"off\")\n",
    "axs[1].imshow(img2, cmap=\"gray\")\n",
    "axs[1].axis(\"off\")\n",
    "# print(img.mean(), img.max(), img.min(), img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "# import cv2\n",
    "import glob\n",
    "\n",
    "# PATH = \"/scratch/ds6516/video_denoising/datasets/Derfs\"\n",
    "PATH = \"/scratch/ds6516/video_denoising/datasets/GoPro\"\n",
    "\n",
    "# videos = [\"park_joy\", \"sunflower\", \"touchdown\", \"tractor\"]\n",
    "videos = [\"hypersmooth\", \"motorbike\", \"rafting\", \"snowboard\"]\n",
    "\n",
    "for name in videos:\n",
    "    video = cv2.VideoCapture(os.path.join(PATH, name, name+\".avi\"))\n",
    "    count = 1\n",
    "    while(True):\n",
    "        ret, frame = video.read()\n",
    "        if ret:\n",
    "            cv2.imwrite(os.path.join(PATH, name, \"%05d.png\" % (count)), frame)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
